{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/martinpella/Projects/imdb-review'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_path = os.getcwd()\n",
    "DATA_PATH = current_path + '/data'\n",
    "train_path = DATA_PATH + '/train'\n",
    "test_path = DATA_PATH + '/test'\n",
    "results_path = current_path + '/results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Flatten, Dense, Dropout, Convolution1D, MaxPooling1D, SpatialDropout1D, Input, concatenate\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Setup data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_path + '/train_df.csv')\n",
    "test_df = pd.read_csv(test_path + '/test_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle_df(df):\n",
    "    indices = np.arange(df.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    df = df.iloc[indices]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shuffle train and test data\n",
    "train_df = shuffle_df(train_df)\n",
    "test_df = shuffle_df(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks don't take plain text as input, they only understand about numeric tensors. So the first thing we need to do is to transform our reviews. One way is applying word segmentation, where the text is divided into its components words. Each word is then transformed into a vector.\n",
    "Keras provides built-in utilities to do it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the vocabulary size will be restricted to the top 5000 most common words in the dataset\n",
    "max_words = 5000\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(train_df['review'])\n",
    "sequences_train = tokenizer.texts_to_sequences(train_df['review'])\n",
    "sequences_test = tokenizer.texts_to_sequences(test_df['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dictionary mapping words (str) to their index (int)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dictionary mapping indices (int) to their word (str)\n",
    "index2word = {v: k for k, v in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'685, 5, 1, 4, 3, 1, 2103, 1883, 1141, 23, 835, 463, 1135, 2, 410, 1063, 4, 921, 187, 33, 3108, 1, 348, 4939, 5, 145, 578, 8, 175, 3050, 389, 134, 1141, 184, 8, 1, 1355, 3249, 8, 1, 510, 4, 1747, 1624, 1534, 14, 4716, 453, 16, 843, 3866, 2154, 2, 3366, 14, 3169, 2, 985, 4716, 2932, 1, 23, 1, 61, 220, 20, 65, 887, 34, 78, 21, 202, 3, 862, 65, 159, 4717, 1, 25, 1442, 35, 5, 398, 53, 1, 862, 1509, 14, 7, 7, 469, 440, 6, 31, 32, 151, 4043, 2, 26, 38, 92, 159, 2, 1141, 1, 510, 2078, 182, 1534, 44, 2064, 3432, 5, 1, 427, 2, 24, 862, 23, 37, 2, 2, 1, 4716, 220, 166, 9, 875, 5, 16, 1, 7, 7, 149, 137, 227, 192, 80, 91, 202, 1768, 1355, 3249, 18, 9, 6, 3, 3210, 2997, 2, 1574, 5, 862, 19, 1534, 2, 1, 174, 3108, 70, 16, 862, 14, 2, 2052, 1751, 4201, 3230, 14, 1, 88, 903, 2155, 164, 3264, 2, 1048, 583, 2095, 3815, 1588, 1376, 1555, 225, 2, 588, 1588, 1196, 2124, 7, 7, 2933, 3264, 1534, 3866, 2154, 1509, 3366'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is our first training review\n",
    "', '.join(map(str, sequences_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"due to the of a the flesh eating zombies are brought under control and become members of society however they perform the dead attend to those living in us 1950s small while zombies around in the wild zone in the town of pre teen ray as robinson lives with parents carrie anne and baker as helen and bill robinson alas the are the only family on their street who do not own a zombie their new neighbors the have six so to keep up the zombie billy as br br unfortunately mr is by an old walker and he her then new and zombies the town meanwhile young ray has grown attached to the boy and his zombie are like and and the robinson family find it difficult to with the br br doesn't go far enough into its own intriguing wild zone but it is a colorful stylish and addition to zombie film ray and the cast perform well with zombie as and owner tim blake nelson as the most memorable pair director andrew and crew including rob gray design photography don music and james design won awards br br 2006 andrew ray carrie anne billy baker\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(index2word[o] for o in sequences_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the distribution of the sequences lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = [np.array([i for i in s]) for s in sequences_train]\n",
    "x_test = [np.array([i for i in s]) for s in sequences_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lens = np.array(list(map(len, x_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1982, 9, 214.02860000000001)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lens.max(), lens.min(), lens.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Maximum sequence length, longer sequences will be truncated and shorter sequences will be padded with zeros at the beggining\n",
    "max_len = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = pad_sequences(x_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,  685,    5,    1,    4,    3,    1,\n",
       "       2103, 1883, 1141,   23,  835,  463, 1135,    2,  410, 1063,    4,\n",
       "        921,  187,   33, 3108,    1,  348, 4939,    5,  145,  578,    8,\n",
       "        175, 3050,  389,  134, 1141,  184,    8,    1, 1355, 3249,    8,\n",
       "          1,  510,    4, 1747, 1624, 1534,   14, 4716,  453,   16,  843,\n",
       "       3866, 2154,    2, 3366,   14, 3169,    2,  985, 4716, 2932,    1,\n",
       "         23,    1,   61,  220,   20,   65,  887,   34,   78,   21,  202,\n",
       "          3,  862,   65,  159, 4717,    1,   25, 1442,   35,    5,  398,\n",
       "         53,    1,  862, 1509,   14,    7,    7,  469,  440,    6,   31,\n",
       "         32,  151, 4043,    2,   26,   38,   92,  159,    2, 1141,    1,\n",
       "        510, 2078,  182, 1534,   44, 2064, 3432,    5,    1,  427,    2,\n",
       "         24,  862,   23,   37,    2,    2,    1, 4716,  220,  166,    9,\n",
       "        875,    5,   16,    1,    7,    7,  149,  137,  227,  192,   80,\n",
       "         91,  202, 1768, 1355, 3249,   18,    9,    6,    3, 3210, 2997,\n",
       "          2, 1574,    5,  862,   19, 1534,    2,    1,  174, 3108,   70,\n",
       "         16,  862,   14,    2, 2052, 1751, 4201, 3230,   14,    1,   88,\n",
       "        903, 2155,  164, 3264,    2, 1048,  583, 2095, 3815, 1588, 1376,\n",
       "       1555,  225,    2,  588, 1588, 1196, 2124,    7,    7, 2933, 3264,\n",
       "       1534, 3866, 2154, 1509, 3366], dtype=int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 500)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_train = np.array(train_df['sentiment']).reshape(-1, 1)\n",
    "labels_test = np.array(test_df['sentiment']).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Modeling</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Simple linear model</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The Embedding layer is a dictionary mapping integer indices (that stand for specific words) to dense vectors. It takes as input integers, it looks up these integers into an internal dictionary, and it returns the associated vectors.\" From the book \"Deep Learning with Python\" of Francois Chollet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([Embedding(input_dim=max_words, output_dim=8, input_length=max_len),\n",
    "                    Flatten(),\n",
    "                    Dense(1, activation='sigmoid')\n",
    "                    ])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 8)            40000     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 4001      \n",
      "=================================================================\n",
      "Total params: 44,001\n",
      "Trainable params: 44,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/4\n",
      "20000/20000 [==============================] - 7s - loss: 0.6122 - acc: 0.6753 - val_loss: 0.4164 - val_acc: 0.8340\n",
      "Epoch 2/4\n",
      "20000/20000 [==============================] - 0s - loss: 0.3168 - acc: 0.8787 - val_loss: 0.2902 - val_acc: 0.8828\n",
      "Epoch 3/4\n",
      "20000/20000 [==============================] - 0s - loss: 0.2361 - acc: 0.9099 - val_loss: 0.2699 - val_acc: 0.8906\n",
      "Epoch 4/4\n",
      "20000/20000 [==============================] - 0s - loss: 0.2012 - acc: 0.9252 - val_loss: 0.2682 - val_acc: 0.8924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4f83502c18>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, labels_train, validation_split=0.2, epochs=4, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_model(model, fname):\n",
    "    model_json = model.to_json()\n",
    "    with open(fname, 'w') as json_file:\n",
    "        json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_model(model, results_path + '/models/linear1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(results_path + '/models/linear1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Simple convolutional neural network</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([Embedding(input_dim=max_words, output_dim=16, input_length=max_len),\n",
    "                    SpatialDropout1D(0.2),\n",
    "                    Dropout(0.2),\n",
    "                    Convolution1D(64, 5, padding='same', activation='relu'),\n",
    "                    Dropout(0.2),\n",
    "                    MaxPooling1D(),\n",
    "                    Flatten(),\n",
    "                    Dense(100, activation='relu'),\n",
    "                    Dropout(0.7),\n",
    "                    Dense(1, activation='sigmoid')])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 16)           80000     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 500, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 500, 64)           5184      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               1600100   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,685,385\n",
      "Trainable params: 1,685,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/4\n",
      "20000/20000 [==============================] - 6s - loss: 0.5921 - acc: 0.6336 - val_loss: 0.3324 - val_acc: 0.8718\n",
      "Epoch 2/4\n",
      "20000/20000 [==============================] - 2s - loss: 0.3255 - acc: 0.8723 - val_loss: 0.2781 - val_acc: 0.8888\n",
      "Epoch 3/4\n",
      "20000/20000 [==============================] - 2s - loss: 0.2557 - acc: 0.9037 - val_loss: 0.2828 - val_acc: 0.8930\n",
      "Epoch 4/4\n",
      "20000/20000 [==============================] - 2s - loss: 0.2209 - acc: 0.9173 - val_loss: 0.2711 - val_acc: 0.8944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4f5de96048>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, labels_train, validation_split=0.2, epochs=4, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_model(model, results_path + '/models/conv1.json')\n",
    "model.save_weights(results_path + '/models/conv1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Pre-trained word embeddings</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous cases, we started with random initializated word vectors. Let's try with pre-trained word vectors. This is similar to use pre-trained convolutional neural networks (as VGG16, ResNet, Inception, etc) in the context of computer vision. We want to take advantage of learned features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec, GloVe and fastText are some of the most famous pre-trained word vectors. In this case I will use GloVe, and in concretely the word vectors trained on English Wikipedia from 2014: https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove_dir = '/home/martinpella/Downloads/GloVe/Wikipedia2014'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "f = open(glove_dir + '/glove.6B.50d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imdb word_index created during tokenization and GloVe embeddings_index have different indices. We need to create a matrix with imdb word_index and GloVe embeddings (in case that they exist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_emb_matrix(max_words, embedding_dim):\n",
    "    embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if i < max_words:\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "            else:\n",
    "                embedding_matrix[i] = np.random.normal(scale=0.6, size=(embedding_dim,))\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = create_emb_matrix(max_words, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([Embedding(max_words, 50, input_length=max_len), \n",
    "                    SpatialDropout1D(0.2),\n",
    "                    Dropout(0.25),\n",
    "                    Convolution1D(64, 5, padding='same', activation='relu'),\n",
    "                    Dropout(0.25),\n",
    "                    MaxPooling1D(),\n",
    "                    Flatten(),\n",
    "                    Dense(100, activation='relu'),\n",
    "                    Dropout(0.85),\n",
    "                    Dense(1, activation='sigmoid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.layers[0].set_weights = [embedding_matrix]\n",
    "model.layers[0].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/4\n",
      "20000/20000 [==============================] - 3s - loss: 0.6689 - acc: 0.5439 - val_loss: 0.4660 - val_acc: 0.7978\n",
      "Epoch 2/4\n",
      "20000/20000 [==============================] - 3s - loss: 0.4047 - acc: 0.8098 - val_loss: 0.2953 - val_acc: 0.8764\n",
      "Epoch 3/4\n",
      "20000/20000 [==============================] - 3s - loss: 0.3008 - acc: 0.8634 - val_loss: 0.2843 - val_acc: 0.8852\n",
      "Epoch 4/4\n",
      "20000/20000 [==============================] - 3s - loss: 0.2525 - acc: 0.9000 - val_loss: 0.2543 - val_acc: 0.9002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4f30405b38>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, labels_train, validation_split=0.2, epochs=4, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.layers[0].trainable = False\n",
    "model.optimizer.lr = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "20000/20000 [==============================] - 3s - loss: 0.2212 - acc: 0.9165 - val_loss: 0.2621 - val_acc: 0.9016\n",
      "Epoch 2/2\n",
      "20000/20000 [==============================] - 3s - loss: 0.2034 - acc: 0.9249 - val_loss: 0.2707 - val_acc: 0.9002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4f0a1b6978>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, labels_train, validation_split=0.2, epochs=2, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_model(model, results_path + '/models/conv2.json')\n",
    "model.save_weights(results_path + '/models/conv2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Multi-size convolutional neural network</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://quid.com/feed/how-quid-uses-deep-learning-with-small-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph_in = Input(shape=(max_words, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "convs = []\n",
    "for filter_size in range(3, 6):\n",
    "    x = Convolution1D(64, filter_size, padding='same', activation='relu')(graph_in)\n",
    "    x = MaxPooling1D()(x)\n",
    "    x = Flatten()(x)\n",
    "    convs.append(x)\n",
    "graph_out = concatenate(convs, axis=1)\n",
    "graph = Model(graph_in, graph_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([Embedding(max_words, 50, input_length=max_len),\n",
    "                    SpatialDropout1D(0.2),\n",
    "                    Dropout(0.2),\n",
    "                    graph,\n",
    "                    Dropout(0.5),\n",
    "                    Dense(100, activation='relu'),\n",
    "                    Dropout(0.85),\n",
    "                    Dense(1, activation='sigmoid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "20000/20000 [==============================] - 7s - loss: 0.4429 - acc: 0.7798 - val_loss: 0.2634 - val_acc: 0.9008\n",
      "Epoch 2/2\n",
      "20000/20000 [==============================] - 6s - loss: 0.2558 - acc: 0.9037 - val_loss: 0.2443 - val_acc: 0.9026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4efbd67748>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, labels_train, validation_split=0.2, epochs=2, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_model(model, results_path + '/models/conv3.json')\n",
    "model.save_weights(results_path + '/models/conv3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
